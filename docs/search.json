[
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "About Me",
    "text": "About Me\n\n\n\n\n\n\nKatie Burak\nAssistant Professor of Teaching, Department of Statistics, UBC https://katieburak.github.io/"
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "https://katieburak.github.io/torus-talk-2026/"
  },
  {
    "objectID": "index.html#attribution",
    "href": "index.html#attribution",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Attribution",
    "text": "Attribution\n\n\nDSCI 200 - Navigating Data: Acquisition, Exploration and Management, UBC ⭐️\nData Privacy Handbook\nDSCI 541: Privacy, Ethics, and Security at UBC\nHarvard University Privacy Tools Project: Differential Privacy\nSTA 199: Introduction to Data Science and Statistical Thinking, Duke University"
  },
  {
    "objectID": "index.html#what-are-you-comfortable-sharing",
    "href": "index.html#what-are-you-comfortable-sharing",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "What Are You Comfortable Sharing?",
    "text": "What Are You Comfortable Sharing?\n\n\nYour favorite type of music\n\nYour Instagram likes and follows\n\nYour e-mail\n\nYour name and DOB\n\nYour GPS location throughout the day\nYour browsing history\nYour private messages/DMs\n\n\n\n\n\nDiscussion:\n\n\nWhich of these data would you feel comfortable sharing with an app?\n\nWhat questions would you want to ask before sharing this data?\n\nWhat if it combined two or three pieces of information?"
  },
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Source: CBC News"
  },
  {
    "objectID": "index.html#section-2",
    "href": "index.html#section-2",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Even something as simple as your Facebook “likes” can reveal a lot more than you think…\nResearchers at Cambridge showed that algorithms could predict:\n\nSexual orientation with up to 88% accuracy\nRace with 95% accuracy\nPolitical affiliation with 85% accuracy\n\nAll from analyzing the pages and posts you “liked” (no profile bio or messages needed)!\n\n\nhttps://www.cam.ac.uk/research/news/digital-records-could-expose-intimate-details-and-personality-traits-of-millions"
  },
  {
    "objectID": "index.html#what-happens-to-your-data",
    "href": "index.html#what-happens-to-your-data",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "What Happens to Your Data?",
    "text": "What Happens to Your Data?\nEvery time you use an app, visit a website, click on a link, fill out a survey or even just scroll on your device, your data is being:\n\n\nCollected - What you click, search, watch, like or buy\n\nAnalyzed - Used to predict your behaviour, interests or identity\n\nShared or Sold - Passed to advertisers, data brokers or other companies"
  },
  {
    "objectID": "index.html#why-does-this-matter",
    "href": "index.html#why-does-this-matter",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Why Does This Matter?",
    "text": "Why Does This Matter?\n\n\nYou may be targeted with ads, content and potentially misinformation\n\nYou could be judged or profiled based on your data (even if it’s not accurate)\nYou rarely know who has your data (or what they’re doing with it)  \nSo what does this mean for us? Let’s explore how data can be used, what makes certain information sensitive and why it matters."
  },
  {
    "objectID": "index.html#personally-identifiable-information-pii",
    "href": "index.html#personally-identifiable-information-pii",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Personally Identifiable Information (PII)",
    "text": "Personally Identifiable Information (PII)\n\nPII refers to any data that can be used to identify a specific individual.\nDirect identifiers: These clearly and uniquely point to a person.\n\nExamples: name, social security number, patient ID\n\nIndirect identifiers: These don’t identify someone on their own, but could when combined.\n\nExamples: age, DOB, postal code, race, sex"
  },
  {
    "objectID": "index.html#personal-data",
    "href": "index.html#personal-data",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Personal Data",
    "text": "Personal Data\nData can be identifiable when:\n\n\nThey contain directly identifying information.\nIt’s possible to single out an individual\nIt’s possible to infer information about an individual based on information in your dataset\nIt’s possible to link records relating to an individual.\nDe-identification is still reversible."
  },
  {
    "objectID": "index.html#scenario-can-this-data-identify-you",
    "href": "index.html#scenario-can-this-data-identify-you",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Scenario: Can This Data Identify You?",
    "text": "Scenario: Can This Data Identify You?\nA fitness app shares anonymized data with researchers. The dataset includes:\n\nStep count per day\nGeneral location (postal code)\nAge\nTime of day the user exercises\nHealth conditions\n\nSeparately, a publicly available dataset includes information from a local running club: names, age groups and 5K race times."
  },
  {
    "objectID": "index.html#the-mosaic-effect",
    "href": "index.html#the-mosaic-effect",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "The Mosaic Effect",
    "text": "The Mosaic Effect\n\nThe “Mosaic Effect” can happens when separate pieces of data, which alone don’t identify anyone, are combined from different sources to reveal personal information or identify an individual.\nIn 2000, 87% of the United States population was found to be identifiable using a combination of their ZIP code, gender and date of birth.\n\n\n\nhttps://dataprivacylab.org/projects/identifiability/paper1.pdf"
  },
  {
    "objectID": "index.html#pseudonymization-and-anonymization",
    "href": "index.html#pseudonymization-and-anonymization",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Pseudonymization and Anonymization",
    "text": "Pseudonymization and Anonymization\n\nPseudonymization and anonymization are techniques to de-identify personal data\nGoal: reduce linkability of data to individuals\nWe will now define each of these terms"
  },
  {
    "objectID": "index.html#pseudonymization",
    "href": "index.html#pseudonymization",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Pseudonymization",
    "text": "Pseudonymization\n\n\nReduces linkability of data to individuals\nData cannot identify individuals without additional information\nOften done by replacing direct identifiers with pseudonyms\nLink between real identifiers and pseudonyms is stored separately\nRe-identification remains possible!"
  },
  {
    "objectID": "index.html#anonymization",
    "href": "index.html#anonymization",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Anonymization",
    "text": "Anonymization\n\n\nData are anonymized when no individual is identifiable (directly or indirectly)\nThis applies even to the data controller\nFully anonymized data are no longer personal data\nAnonymization is difficult to achieve in practice"
  },
  {
    "objectID": "index.html#identifiability-spectrum",
    "href": "index.html#identifiability-spectrum",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Identifiability Spectrum",
    "text": "Identifiability Spectrum\n\nIdentifiability is a spectrum\nMore de-identified data = closer to anonymized\nLower identifiability = lower re-identification risk\n\n\n\nhttps://www.kdnuggets.com/2020/08/anonymous-anonymized-data.html"
  },
  {
    "objectID": "index.html#when-are-data-truly-anonymous",
    "href": "index.html#when-are-data-truly-anonymous",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "When Are Data Truly anonymous?",
    "text": "When Are Data Truly anonymous?\n\nOnly if re-identification would require unreasonable effort (factors include cost, time and available technology)\nData are not anonymous if:\n\n\n\nDirect identifiers are present\nIndividuals can be singled out from a group\nRe-identification possible via linking datasets (mosaic effect)\nInference about identity is possible (e.g., through different variables)\nDe-identification can be reversed"
  },
  {
    "objectID": "index.html#de-identification-techniques",
    "href": "index.html#de-identification-techniques",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "De-identification Techniques",
    "text": "De-identification Techniques\nTechniques to deidentify your data include:\n\nSuppression\nGeneralization\nReplacement\nTop- and bottom coding\nAdding noise\nPermutation"
  },
  {
    "objectID": "index.html#section-3",
    "href": "index.html#section-3",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "First, let’s generate some data we can use to help illustrate these concepts.\n\nlibrary(tidyverse)\n\ndf &lt;- tibble(\n  name = c(\"Joel Miller\", \"Ellie Williams\", \"Tommy Miller\", \"Abby Anderson\"),\n  age = c(52, 19, 48, 28),\n  height_cm = c(182, 160, 185,173) \n)\n\ndf\n\n# A tibble: 4 × 3\n  name             age height_cm\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 Joel Miller       52       182\n2 Ellie Williams    19       160\n3 Tommy Miller      48       185\n4 Abby Anderson     28       173"
  },
  {
    "objectID": "index.html#suppression",
    "href": "index.html#suppression",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Suppression",
    "text": "Suppression\n\n\nRemove entire variables, values or records\nUsed to eliminate highly identifying or unnecessary data\nExamples:\n\nNames, contact details, social security numbers\nGPS metadata, IP addresses, neuroimaging facial features\nOutliers or unique participants"
  },
  {
    "objectID": "index.html#suppression-example",
    "href": "index.html#suppression-example",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Suppression Example",
    "text": "Suppression Example\n\ndf_suppressed &lt;- df |&gt;\n  select(-name)\n\ndf_suppressed\n\n# A tibble: 4 × 2\n    age height_cm\n  &lt;dbl&gt;     &lt;dbl&gt;\n1    52       182\n2    19       160\n3    48       185\n4    28       173"
  },
  {
    "objectID": "index.html#generalization",
    "href": "index.html#generalization",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Generalization",
    "text": "Generalization\n\n\nReduces detail or granularity in the data\nMakes individuals harder to single out\nExamples:\n\nConvert date of birth to age, or group into ranges\nReplace address with town or region\nRecategorize rare labels into “other” or “missing”\nAbstract people or places in qualitative data (e.g., “Bob” to “[colleague]”)"
  },
  {
    "objectID": "index.html#section-4",
    "href": "index.html#section-4",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Here we will show an example of generalization on the age column:\n\ndf_generalized &lt;- df |&gt;\n  mutate(age_group = case_when(\n    age &lt; 30 ~ \"under 30\",\n    TRUE     ~ \"30+\"\n  ))|&gt;\n  select(-age)\n\ndf_generalized\n\n# A tibble: 4 × 3\n  name           height_cm age_group\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;    \n1 Joel Miller          182 30+      \n2 Ellie Williams       160 under 30 \n3 Tommy Miller         185 30+      \n4 Abby Anderson        173 under 30"
  },
  {
    "objectID": "index.html#replacement",
    "href": "index.html#replacement",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Replacement",
    "text": "Replacement\n\n\nSwap identifying info with less informative alternatives\nExamples:\n\nUse pseudonyms for names (with securely stored keyfile)\nReplace with placeholders (e.g., “[redacted]”)\nRounding numeric values"
  },
  {
    "objectID": "index.html#creating-pseudonyms",
    "href": "index.html#creating-pseudonyms",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Creating Pseudonyms",
    "text": "Creating Pseudonyms\n\n\nPseudonyms should reveal nothing about the subject\nGood pseudonyms:\n\nAre random or meaningless strings/numbers\nAre securely managed (e.g., encrypted keyfile)\n\nCan be generated using tools in Excel, R, Python, SPSS"
  },
  {
    "objectID": "index.html#replacement-with-pseudonyms",
    "href": "index.html#replacement-with-pseudonyms",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Replacement with Pseudonyms",
    "text": "Replacement with Pseudonyms\n\ndf_pseudonymized &lt;- df |&gt;\n  mutate(pseudonym = paste0(\"ID\", row_number())) |&gt;\n  select(pseudonym, everything(), -name)\n\ndf_pseudonymized\n\n# A tibble: 4 × 3\n  pseudonym   age height_cm\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 ID1          52       182\n2 ID2          19       160\n3 ID3          48       185\n4 ID4          28       173"
  },
  {
    "objectID": "index.html#hashing",
    "href": "index.html#hashing",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Hashing",
    "text": "Hashing\n\nHashing converts names into fixed-length, irreversible strings.\nUnlike pseudonyms, hashed values cannot be easily reversed.\nIn R, we can use the digest package (and function) to hash."
  },
  {
    "objectID": "index.html#section-5",
    "href": "index.html#section-5",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "library(digest) \n\ndf_hashed &lt;- df |&gt;\n  rowwise() |&gt;\n  mutate(name_hash = digest(name)) |&gt;\n  select(name_hash, everything(), -name)\n\ndf_hashed\n\n# A tibble: 4 × 3\n# Rowwise: \n  name_hash                          age height_cm\n  &lt;chr&gt;                            &lt;dbl&gt;     &lt;dbl&gt;\n1 4a3e0ee26ab3fb1338e893f4d4e7244b    52       182\n2 201943dd66d423ed3cce2242a75736d4    19       160\n3 81699ec9483bad176eed57ee43ffa010    48       185\n4 046dff9ba9cf33573396f4de8c0c0e0b    28       173"
  },
  {
    "objectID": "index.html#top--and-bottom-coding",
    "href": "index.html#top--and-bottom-coding",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Top- and Bottom-Coding",
    "text": "Top- and Bottom-Coding\n\n\nLimits extreme values in quantitative data\nRecode all values above or below a threshold\nExample: all incomes above $150,000 become $150,000\nPreserves much of the dataset, but distorts distribution tails"
  },
  {
    "objectID": "index.html#top-coding-example",
    "href": "index.html#top-coding-example",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Top-coding example",
    "text": "Top-coding example\n\nConsider 6ft (182.88cm) is considered our maximum height threshold.\n\n\ndf_top_coded &lt;- df |&gt;\n  mutate(height_cm = if_else(height_cm &gt; 182.88, 182.88, height_cm))\n\ndf_top_coded\n\n# A tibble: 4 × 3\n  name             age height_cm\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n1 Joel Miller       52      182 \n2 Ellie Williams    19      160 \n3 Tommy Miller      48      183.\n4 Abby Anderson     28      173"
  },
  {
    "objectID": "index.html#adding-noise",
    "href": "index.html#adding-noise",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Adding Noise",
    "text": "Adding Noise\n\nIntroduces randomness to protect sensitive info\nExamples:\n\nAdd a small random amount to numeric values\nBlur images or alter voices"
  },
  {
    "objectID": "index.html#adding-noise-to-height",
    "href": "index.html#adding-noise-to-height",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Adding Noise to Height",
    "text": "Adding Noise to Height\n\nset.seed(200) \n\ndf_noisy &lt;- df |&gt;\n  mutate(height_cm_noisy = height_cm + rnorm(n(), mean = 0, sd = 2)) |&gt;\n    select(-height_cm)\n\ndf_noisy\n\n# A tibble: 4 × 3\n  name             age height_cm_noisy\n  &lt;chr&gt;          &lt;dbl&gt;           &lt;dbl&gt;\n1 Joel Miller       52            182.\n2 Ellie Williams    19            160.\n3 Tommy Miller      48            186.\n4 Abby Anderson     28            174."
  },
  {
    "objectID": "index.html#permutation",
    "href": "index.html#permutation",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Permutation",
    "text": "Permutation\n\n\nSwap values between individuals\nMakes linking variables across a record more difficult\nMaintains distributions, but breaks correlations\nCan limit the types of analyses possible"
  },
  {
    "objectID": "index.html#permutation-of-height-values",
    "href": "index.html#permutation-of-height-values",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Permutation of Height Values",
    "text": "Permutation of Height Values\n\nset.seed(200)\n\ndf_permuted &lt;- df |&gt;\n  mutate(height_cm_permuted = sample(height_cm)) |&gt;\n    select(-height_cm)\n\ndf_permuted\n\n# A tibble: 4 × 3\n  name             age height_cm_permuted\n  &lt;chr&gt;          &lt;dbl&gt;              &lt;dbl&gt;\n1 Joel Miller       52                160\n2 Ellie Williams    19                173\n3 Tommy Miller      48                182\n4 Abby Anderson     28                185"
  },
  {
    "objectID": "index.html#privacy-vs.-utility-tradeoff",
    "href": "index.html#privacy-vs.-utility-tradeoff",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Privacy vs. Utility Tradeoff",
    "text": "Privacy vs. Utility Tradeoff\n\n\nhttps://www.researchgate.net/figure/Trade-off-between-privacy-level-and-utility-level-of-data_fig1_357987903"
  },
  {
    "objectID": "index.html#case-study-brogan-inc.-and-nihb-data",
    "href": "index.html#case-study-brogan-inc.-and-nihb-data",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Case Study: Brogan Inc. and NIHB Data",
    "text": "Case Study: Brogan Inc. and NIHB Data\n\nThe Non-Insured Health Benefits (NIHB) database contains sensitive health data on First Nations use of services like prescriptions, dental care, and medical devices.\nIn 2001, Health Canada began releasing de-identified NIHB pharmacy claims data to Brogan Inc., a private health consulting firm.\nThough personal identifiers were removed, community identifiers remained, and First Nations were not informed until 2007.\nBrogan sold the data to pharmaceutical companies for commercial research and marketing\nHealth Canada justified the release by claiming no privacy interests remained since personally identifying information had been removed.\n\n\nKukutai, T., & Taylor, J. (2016). Indigenous data sovereignty: Toward an agenda. ANU press."
  },
  {
    "objectID": "index.html#discussion",
    "href": "index.html#discussion",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Discussion",
    "text": "Discussion\n\nWas the data truly de-identified?\nWhat are the limits of simply removing names and IDs from a dataset?\nHow can we measure whether a dataset is truly “safe” to release?\nShould de-identified data still require community consent before being shared or sold?"
  },
  {
    "objectID": "index.html#why-basic-deidentification-isnt-always-enough",
    "href": "index.html#why-basic-deidentification-isnt-always-enough",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Why basic deidentification isn’t always enough",
    "text": "Why basic deidentification isn’t always enough\n\nIndividuals can often be re-identified using other information.\nAs datasets become more detailed and linkable, privacy risks increase.\nMore advanced statistical methods are often needed to ensure meaningful deidentification while preserving data utility."
  },
  {
    "objectID": "index.html#statistical-approaches-to-deidentification",
    "href": "index.html#statistical-approaches-to-deidentification",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Statistical approaches to deidentification",
    "text": "Statistical approaches to deidentification\n\n\n\\(k\\)-anonymity\n\n\\(l\\)-diversity\n\nDifferential privacy (advanced)"
  },
  {
    "objectID": "index.html#overview-of-privacy-models",
    "href": "index.html#overview-of-privacy-models",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Overview of privacy models",
    "text": "Overview of privacy models\n\n\\(k\\)-anonymity and \\(l\\)-diversity are statistical approaches that quantify the level of identifiability within a tabular dataset.\n\nThey focus on how variables combined can lead to identification.\n\nThese approaches are complementary: a dataset can be simultaneously \\(k\\)-anonymous and \\(l\\)-diverse, where \\(k\\) and \\(l\\) represent numeric thresholds.\n\\(k\\)-anonymity and \\(l\\)-diversityare typically used to de-identify tabular datasets before sharing.\nThey work best on relatively large datasets, where enough observations are present to preserve useful detail while still protecting privacy."
  },
  {
    "objectID": "index.html#identifiers-quasi-identifiers-and-sensitive-attributes",
    "href": "index.html#identifiers-quasi-identifiers-and-sensitive-attributes",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Identifiers, Quasi-Identifiers, and Sensitive Attributes",
    "text": "Identifiers, Quasi-Identifiers, and Sensitive Attributes\nPrivacy models distinguish between three types of variables:\n\nIdentifiers: Direct identifiers such as names, student numbers, email addresses.\nQuasi-Identifiers: Indirect identifiers that can lead to identification when combined with other quasi-identifiers or external data.\n\nExamples: age, sex, place of residence, physical characteristics, timestamps, etc.\n\nSensitive Attributes: Variables of interest that need protection and cannot be altered as they are key outcomes.\n\nExamples: Medical condition, Income, etc."
  },
  {
    "objectID": "index.html#importance-of-correct-variable-categorization",
    "href": "index.html#importance-of-correct-variable-categorization",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Importance of Correct Variable Categorization",
    "text": "Importance of Correct Variable Categorization\n\n\nCorrectly categorizing variables into identifiers, quasi-identifiers, and sensitive attributes is crucial.\n\nThis categorization determines how to de-identify your dataset effectively using \\(k\\)-anonymity, \\(l\\)-diversity, and \\(t\\)-closeness.\nNow, let’s discuss each of these techniques in detail…"
  },
  {
    "objectID": "index.html#k-anonymity",
    "href": "index.html#k-anonymity",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "\\(k\\)-anonymity",
    "text": "\\(k\\)-anonymity\n\n\nA data set is \\(k\\)-anonymous if each observation cannot be distinguished from at least \\(k-1\\) other observations based on the quasi-identifiers.\n\nThis can be achieved through generalization, suppression and sometimes top- or bottom-coding of data values.\nApplying \\(k\\)-anonymity makes it more difficult for an attacker to single out or re-identify specific individuals.\n\nIt also helps reduce the risk of the mosaic effect, where combining data points could lead to identification."
  },
  {
    "objectID": "index.html#making-a-data-set-k-anonymous",
    "href": "index.html#making-a-data-set-k-anonymous",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Making a data set \\(k\\)-anonymous",
    "text": "Making a data set \\(k\\)-anonymous\n\n\nIdentify variables as identifiers, quasi-identifiers and sensitive attributes.\n\nChoose a value for \\(k\\).\n\nAggregate or transform the data so each combination of quasi-identifiers occurs at least k times."
  },
  {
    "objectID": "index.html#choosing-k",
    "href": "index.html#choosing-k",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Choosing \\(k\\)",
    "text": "Choosing \\(k\\)\n\nThere is no single correct value for \\(k\\)!\nHigher \\(k\\) increases privacy, but reduces data detail and utility.\n\nThe choice depends on promises made to data subjects and acceptable risk levels.\n\n\n\n Source: k2view.com"
  },
  {
    "objectID": "index.html#example-data",
    "href": "index.html#example-data",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Example data",
    "text": "Example data\n\nAge and city are quasi-identifiers, and salary is considered a sensitive attribute.\n\n\n\n\n\nAge\n\n\nCity\n\n\nSalary\n\n\n\n\n\n\n38\n\n\nCalgary\n\n\n91,000\n\n\n\n\n37\n\n\nToronto\n\n\n92,000\n\n\n\n\n31\n\n\nVancouver\n\n\n82,000\n\n\n\n\n48\n\n\nCalgary\n\n\n115,000\n\n\n\n\n39\n\n\nVancouver\n\n\n118,000\n\n\n\n\n37\n\n\nCalgary\n\n\n97,000\n\n\n\n\n34\n\n\nToronto\n\n\n98,000\n\n\n\n\n33\n\n\nVancouver\n\n\n89,000\n\n\n\n\n32\n\n\nToronto\n\n\n108,000\n\n\n\n\n45\n\n\nCalgary\n\n\n95,000"
  },
  {
    "objectID": "index.html#k2",
    "href": "index.html#k2",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "\\(k=2\\)",
    "text": "\\(k=2\\)\n\n\n\n\nAge Range\n\n\nCity\n\n\nSalary Range\n\n\n\n\n\n\n30–39\n\n\nCalgary\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\nToronto\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\nVancouver\n\n\n80,000–89,999\n\n\n\n\n40–49\n\n\nCalgary\n\n\n110,000–119,999\n\n\n\n\n30–39\n\n\nVancouver\n\n\n110,000–119,999\n\n\n\n\n30–39\n\n\nCalgary\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\nToronto\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\nVancouver\n\n\n80,000–89,999\n\n\n\n\n30–39\n\n\nToronto\n\n\n100,000–109,999\n\n\n\n\n40–49\n\n\nCalgary\n\n\n90,000–99,999"
  },
  {
    "objectID": "index.html#section-6",
    "href": "index.html#section-6",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Given the data, which field(s) could you generalize to help achieve k = 3 anonymity?\n\n\n\n\nAge\nZIP Code\nDisease\n\n\n\n\n29\n13053\nFlu\n\n\n27\n13068\nFlu\n\n\n28\n13068\nCold\n\n\n45\n14853\nDiabetes\n\n\n46\n14853\nDiabetes\n\n\n47\n14853\nCancer\n\n\n\n\n\nA. Generalize Age into age ranges (e.g., 20–29, 40–49)\n\nB. Suppress Disease entirely\n\nC. Generalize ZIP Code to first 3 digits (e.g., 130, 148)\n\nD. Generalize Age into age ranges (e.g., 20–29, 40–49) and ZIP code to first 3 digits (e.g., 130, 148)\n\nE. It’s already \\(k=3\\) anonymous"
  },
  {
    "objectID": "index.html#section-7",
    "href": "index.html#section-7",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Which of the following datasets violates \\(k = 2\\) anonymity?\n\n\nOption A\n\n\n\nAge\nSex\nZIP\n\n\n\n\n34\nM\n02138\n\n\n34\nM\n02138\n\n\n34\nF\n02139\n\n\n\n\nOption B\n\n\n\nAge\nSex\nZIP\n\n\n\n\n22\nF\n10011\n\n\n22\nF\n10011\n\n\n22\nF\n10011\n\n\n\n\nOption C\n\n\n\nAge Range\nSex\nZIP Prefix\n\n\n\n\n30–39\n*\n021**\n\n\n30–39\n*\n021**\n\n\n30–39\n*\n021**\n\n\n\n\n\nA. Only A\n\nB. Only B\n\nC. Only C\n\nD. A and B"
  },
  {
    "objectID": "index.html#l-diversity",
    "href": "index.html#l-diversity",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "\\(l\\)-diversity",
    "text": "\\(l\\)-diversity\n\n\\(l\\)-diversity is an extension of \\(k\\)-anonymity that ensures sufficient variation in a sensitive attribute.\nThis is important because if all individuals within a group share the same sensitive value, there is still a risk of inference."
  },
  {
    "objectID": "index.html#section-8",
    "href": "index.html#section-8",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Although these data are \\(2\\)-anonymous, we can still infer that any 30-39 year old from Calgary who participated earns between 90-99k.\n\n\n\n\n\nAge Range\n\n\nCity\n\n\nSalary Range\n\n\n\n\n\n\n30–39\n\n\nCalgary\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\nToronto\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\nVancouver\n\n\n80,000–89,999\n\n\n\n\n40–49\n\n\nCalgary\n\n\n110,000–119,999\n\n\n\n\n30–39\n\n\nVancouver\n\n\n110,000–119,999\n\n\n\n\n30–39\n\n\nCalgary\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\nToronto\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\nVancouver\n\n\n80,000–89,999\n\n\n\n\n30–39\n\n\nToronto\n\n\n100,000–109,999\n\n\n\n\n40–49\n\n\nCalgary\n\n\n90,000–99,999"
  },
  {
    "objectID": "index.html#l-diversity-1",
    "href": "index.html#l-diversity-1",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "\\(l\\)-diversity",
    "text": "\\(l\\)-diversity\n\nThe approach requires at least \\(l\\) different values for the sensitive attribute within each combination of quasi-identifiers.\nAgain, there is no perfect value for \\(l\\) (typically \\(1&lt; l \\leq k\\))."
  },
  {
    "objectID": "index.html#section-9",
    "href": "index.html#section-9",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "With \\(l=2\\), that means that for each combination of Age Range and City, there are at least 2 distinct Salary Ranges.\n\n\n\n\n\nAge Range\n\n\nCity\n\n\nSalary Range\n\n\n\n\n\n\n30–39\n\n\n-\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\n-\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\n-\n\n\n80,000–89,999\n\n\n\n\n40–49\n\n\nCalgary\n\n\n110,000–119,999\n\n\n\n\n30–39\n\n\n-\n\n\n110,000–119,999\n\n\n\n\n30–39\n\n\n-\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\n-\n\n\n90,000–99,999\n\n\n\n\n30–39\n\n\n-\n\n\n80,000–89,999\n\n\n\n\n30–39\n\n\n-\n\n\n100,000–109,999\n\n\n\n\n40–49\n\n\nCalgary\n\n\n90,000–99,999"
  },
  {
    "objectID": "index.html#section-10",
    "href": "index.html#section-10",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Consider this 3-anonymous dataset. Is it also 2-diverse with respect to “Condition”?\n\n\n\n\nAge Range\nZIP Prefix\nCondition\n\n\n\n\n20–29\n130**\nFlu\n\n\n20–29\n130**\nFlu\n\n\n20–29\n130**\nFlu\n\n\n30–39\n148**\nCold\n\n\n30–39\n148**\nCold\n\n\n30–39\n148**\nCancer\n\n\n\n\n\nA. Yes, both groups have 2 or more different values\n\nB. No, one group violates l-diversity\n\nC. Yes, because the dataset is already k-anonymous\n\nD. No, both groups have only one distinct value"
  },
  {
    "objectID": "index.html#there-are-still-issues",
    "href": "index.html#there-are-still-issues",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "There are still issues…",
    "text": "There are still issues…\n\nEven though the data is de-identified, some sensitive patterns can still leak through.\nIn the example we discussed, both individuals are grouped into the same age range and city.\nWhile they are in different salary ranges and exact values are hidden, the range is still quite narrow.\nDue to the similarity of the salary ranges, one can still infer that both individuals earn between $90,000 and $119,999.\n\n\n\n\n\nAge Range\n\n\nCity\n\n\nSalary Range\n\n\n\n\n\n\n40–49\n\n\nCalgary\n\n\n110,000–119,999\n\n\n\n\n40–49\n\n\nCalgary\n\n\n90,000–99,999"
  },
  {
    "objectID": "index.html#differential-privacy",
    "href": "index.html#differential-privacy",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Differential privacy",
    "text": "Differential privacy\n\nSo, we may need more sophisticated tools to privatize our data…\nDifferential privacy is a mathematical approach to protecting privacy\nIt ensures algorithm results are nearly the same whether one person’s data is included or not\nDifferential privacy makes it hard to tell if any individual’s data is in the dataset, which protects individual’s information (even with unusual or unique data)"
  },
  {
    "objectID": "index.html#section-11",
    "href": "index.html#section-11",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Source: https://medium.com/data-science/a-differential-privacy-example-for-beginners-ef3c23f69401"
  },
  {
    "objectID": "index.html#open-science",
    "href": "index.html#open-science",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Open Science",
    "text": "Open Science\n\n\n\nOpen science is about making scientific research, data, and dissemination accessible to all.\n\nIt promotes transparency, collaboration, and innovation in research.\n\nIncludes open access publications, open data and open tools.\nSupported by initiatives like FOSTER (Facilitate Open Science Training for European Research)."
  },
  {
    "objectID": "index.html#what-are-open-data",
    "href": "index.html#what-are-open-data",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "What are Open Data?",
    "text": "What are Open Data?\n\n\n\nOpen data refers to freely accessible, online data that can be used, reused, and shared with proper attribution given to the original source (FOSTER).\nSharing and reusing open data helps make research more transparent and reproducible.\n\nEthical considerations mean that not all data can (or should) be fully open (e.g., personal or sensitive data)."
  },
  {
    "objectID": "index.html#why-open-data-matters",
    "href": "index.html#why-open-data-matters",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Why Open Data Matters",
    "text": "Why Open Data Matters\n\n\n\nReproducibility: Enables verification and replication of research.\n\nEfficiency: Saves time and resources by reducing redundant data collection.\n\nCollaboration: Allows researchers to combine datasets for new insights.\n\nInnovation: Drives new discoveries and applications across disciplines."
  },
  {
    "objectID": "index.html#data-ownership-licensing",
    "href": "index.html#data-ownership-licensing",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Data Ownership & Licensing",
    "text": "Data Ownership & Licensing\n\n\nUnderstanding data ownership is essential before sharing or licensing data.\n\nOwnership depends on factors like:\n\nWho collected or created the data.\n\nInstitutional policies and employment contracts.\n\nFunding agency requirements and agreements.\n\nThe nature of the data - personal data may be subject to privacy laws (refer back to the Amazon example)."
  },
  {
    "objectID": "index.html#balancing-openness-ethics",
    "href": "index.html#balancing-openness-ethics",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Balancing Openness & Ethics",
    "text": "Balancing Openness & Ethics\n\n\n\nOpen science supports open data whenever ethically appropriate.\n\nSome data must remain restricted due to privacy, security, or legal constraints.\n\nBest practices help balance openness with responsibility.\n\nOpen data and open science movements often overlook marginalized individual’s rights and interests (e.g., Indigenous data).\n\nThe goal: “As open as possible, as closed as necessary.”"
  },
  {
    "objectID": "index.html#key-takeaways",
    "href": "index.html#key-takeaways",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nData exists on a spectrum of identifiability\nEven seemingly anonymous data can often be re-identified (e.g., mosaic effect)\nQuasi-identifiers can lead to re-identification if not protected\n\nChoosing privacy parameters involves balancing risk and data utility\nResponsible data handling requires both technical skill and ethical awareness"
  },
  {
    "objectID": "index.html#section-12",
    "href": "index.html#section-12",
    "title": "An Introduction to Data Privacy in Practice",
    "section": "",
    "text": "Questions?"
  }
]